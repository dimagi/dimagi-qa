name: Metrics Collector

on:
  workflow_run:
    workflows:
      - "HQ Smoke Tests"
      - "Python Request API"
      - "CO BHA Smoke Tests"
      - "Lookup table Tests"
      - "Case Search Tests"
      - "Case Search Split Screen Tests"
      - "Data Dictionary Tests"
      - "Elastic Search Tests"
      - "Export Tests"
      - "Find Data by ID Tests"
      - "Formplayer Tests"
      - "Multi Select Tests"
      - "Priority Escape Defects Tests"
      - "Power BI Tests"
    types: [completed]

  workflow_dispatch:
    inputs:
      run_id:
        description: "Optional: specific run_id"
        required: false
        default: ""
      latest_runs:
        description: "If run_id blank, ingest latest N runs"
        required: false
        default: "10"

  schedule:
    - cron: "30 18 * * *" # 12:00 AM IST

permissions:
  contents: write
  actions: read
  pages: write
  id-token: write

concurrency:
  group: metrics-collector
  cancel-in-progress: false

jobs:
  collect:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout metrics branch
        uses: actions/checkout@v4
        with:
          ref: metrics
          fetch-depth: 0

      - name: Build list of run_ids
        id: ingest
        uses: actions/github-script@v7
        with:
          script: |
            const owner = context.repo.owner;
            const repo = context.repo.repo;

            if (context.eventName === "workflow_run") {
              core.setOutput("ids", JSON.stringify([context.payload.workflow_run.id]));
              return;
            }

            const rid = (core.getInput("run_id") || "").trim();
            if (rid) {
              core.setOutput("ids", JSON.stringify([Number(rid)]));
              return;
            }

            const n = Number(core.getInput("latest_runs") || "10");
            const res = await github.rest.actions.listWorkflowRunsForRepo({
              owner, repo, status: "completed", per_page: n
            });
            core.setOutput("ids", JSON.stringify(res.data.workflow_runs.map(r => r.id)));

      - name: Download run-summary artifacts
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require("fs");
            const ids = JSON.parse(`${{ steps.ingest.outputs.ids }}`);
            fs.mkdirSync("incoming", { recursive: true });

            for (const id of ids) {
              const arts = await github.rest.actions.listWorkflowRunArtifacts({
                owner: context.repo.owner,
                repo: context.repo.repo,
                run_id: id
              });

              for (const a of arts.data.artifacts.filter(x => x.name.startsWith("run-summary"))) {
                const dl = await github.rest.actions.downloadArtifact({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  artifact_id: a.id,
                  archive_format: "zip"
                });
                fs.writeFileSync(`incoming/${id}__${a.name}.zip`, Buffer.from(dl.data));
              }
            }

      - name: Unzip artifacts
        run: |
          set -e
          for z in incoming/*.zip; do
            d="${z%.zip}"
            mkdir -p "$d"
            unzip -o "$z" -d "$d" >/dev/null
          done

      - name: Append to metrics dataset
        run: |
          set -e
          mkdir -p metrics
          touch metrics/runs.jsonl

          while IFS= read -r f; do
            parent="$(basename "$(dirname "$f")")"
            env="${parent#*__run-summary-}"
            [ "$env" = "$parent" ] && env="unknown"

            python - "$f" "$env" >> metrics/runs.jsonl <<'PY'
          import json, sys
          path = sys.argv[1]
          env  = sys.argv[2]

          with open(path, "r", encoding="utf-8") as fh:
              obj = json.load(fh)

          obj.setdefault("env", env)
          obj.setdefault("environment", env)

          print(json.dumps(obj, ensure_ascii=False))
          PY
          done < <(find incoming -name "run_summary.json" | sort)

      - name: Commit and push
        run: |
          git config user.name "metrics-bot"
          git config user.email "metrics-bot@users.noreply.github.com"
          git add metrics/runs.jsonl
          git commit -m "Metrics update (${GITHUB_RUN_ID})" || echo "No changes"
          git push origin metrics

  publish_dashboard:
    needs: collect
    runs-on: ubuntu-latest
    environment:
      name: github-pages
    steps:
      - uses: actions/checkout@v4
        with:
          ref: metrics

      - run: |
          rm -rf site
          mkdir -p site/data
          cp dashboard/index.html site/index.html
          cp metrics/runs.jsonl site/data/runs.jsonl

      - uses: actions/upload-pages-artifact@v3
        with:
          path: site

      - uses: actions/deploy-pages@v4

  daily_digest:
    needs: publish_dashboard
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          ref: metrics
          fetch-depth: 0

      - name: Build Slack summary from metrics
        id: summary
        run: |
          python <<'PY'
          import json, datetime
          from collections import defaultdict
  
          now = datetime.datetime.utcnow()
          cutoff = now - datetime.timedelta(hours=24)
  
          env_stats = defaultdict(lambda: {"pass": 0, "fail": 0})
          total = 0
  
          with open("metrics/runs.jsonl") as f:
            for line in f:
              r = json.loads(line)
              ts = r.get("timestamp_utc")
              if not ts:
                continue
  
              t = datetime.datetime.fromisoformat(ts.replace("Z","+00:00"))
              if t < cutoff:
                continue
  
              env = r.get("env") or r.get("environment") or "unknown"
              status = (r.get("status") or "").lower()
  
              total += 1
              if status == "pass":
                env_stats[env]["pass"] += 1
              else:
                env_stats[env]["fail"] += 1
  
          lines = [
            f"â€¢ {env} â†’ âœ… {s['pass']} pass | âŒ {s['fail']} fail"
            for env, s in env_stats.items()
          ]
  
          fail_total = sum(v["fail"] for v in env_stats.values())
          fail_rate = round((fail_total / total * 100), 1) if total else 0
  
          text = (
            "ðŸ“Š *QA Automation Dashboard (last 24h)*\n\n"
            "*Environment summary:*\n"
            + ("\n".join(lines) if lines else "_No runs in last 24h_")
            + f"\n\nRuns: *{total}*\n"
            + f"Fail rate: *{fail_rate}%*\n\n"
            + "ðŸ”— https://dimagi.github.io/dimagi-qa/"
          )
  
          print(text)
          PY > slack_message.txt

      - name: Post or update Slack message
        env:
          SLACK_TOKEN: ${{ secrets.SLACK_QA_BOT_TOKEN }}
          CHANNEL_ID: ${{ secrets.SLACK_CHANNEL_ID_DASHBOARD }}
        run: |
          set -e
          MESSAGE="$(cat slack_message.txt)"
  
          STATE_FILE="metrics/slack_state.json"
          mkdir -p metrics
          [ -f "$STATE_FILE" ] || echo "{}" > "$STATE_FILE"
  
          TS=$(jq -r '.dashboard_message_ts // empty' "$STATE_FILE")
  
          if [ -n "$TS" ]; then
            echo "Updating existing Slack message $TS"
            RESP=$(curl -s -X POST https://slack.com/api/chat.update \
              -H "Authorization: Bearer $SLACK_TOKEN" \
              -H "Content-type: application/json" \
              --data "$(jq -n \
                --arg channel "$CHANNEL_ID" \
                --arg ts "$TS" \
                --arg text "$MESSAGE" \
                '{channel:$channel, ts:$ts, text:$text}')")
          else
            echo "Posting new Slack message"
            RESP=$(curl -s -X POST https://slack.com/api/chat.postMessage \
              -H "Authorization: Bearer $SLACK_TOKEN" \
              -H "Content-type: application/json" \
              --data "$(jq -n \
                --arg channel "$CHANNEL_ID" \
                --arg text "$MESSAGE" \
                '{channel:$channel, text:$text}')")
  
            TS=$(echo "$RESP" | jq -r '.ts')
            jq --arg ts "$TS" '.dashboard_message_ts=$ts' "$STATE_FILE" > tmp.json
            mv tmp.json "$STATE_FILE"
          fi

      - name: Commit Slack state
        run: |
          git config user.name "metrics-bot"
          git config user.email "metrics-bot@users.noreply.github.com"
          git add metrics/slack_state.json
          git commit -m "Update Slack dashboard message state" || echo "No changes"
          git push origin metrics
  
