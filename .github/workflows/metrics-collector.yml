name: Metrics Collector

on:
  workflow_run:
    workflows:
      - "HQ Smoke Tests"
      - "Python Request API"
      - "CO BHA Smoke Tests"
      - "Lookup table Tests"
      - "Case Search Tests"
      - "Case Search Split Screen Tests"
      - "Data Dictionary Tests"
      - "Elastic Search Tests"
      - "Export Tests"
      - "Find Data by ID Tests"
      - "Formplayer Tests"
      - "Multi Select Tests"
      - "Priority Escape Defects Tests"
      - "Power BI Tests"
    types: [completed]

  workflow_dispatch:
    inputs:
      run_id:
        description: "Optional: specific run_id"
        required: false
        default: ""
      latest_runs:
        description: "If run_id blank, ingest latest N runs"
        required: false
        default: "10"

  schedule:
    - cron: "30 18 * * *" # 12:00 AM IST

permissions:
  contents: write
  actions: read
  pages: write
  id-token: write

concurrency:
  group: metrics-collector
  cancel-in-progress: false

jobs:
  collect:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout metrics branch
        uses: actions/checkout@v4
        with:
          ref: metrics
          fetch-depth: 0

      - name: Build list of run_ids
        id: ingest
        uses: actions/github-script@v7
        with:
          script: |
            const owner = context.repo.owner;
            const repo = context.repo.repo;

            if (context.eventName === "workflow_run") {
              core.setOutput("ids", JSON.stringify([context.payload.workflow_run.id]));
              return;
            }

            const rid = (core.getInput("run_id") || "").trim();
            if (rid) {
              core.setOutput("ids", JSON.stringify([Number(rid)]));
              return;
            }

            const n = Number(core.getInput("latest_runs") || "10");
            const res = await github.rest.actions.listWorkflowRunsForRepo({
              owner, repo, status: "completed", per_page: n
            });
            core.setOutput("ids", JSON.stringify(res.data.workflow_runs.map(r => r.id)));

      - name: Download run-summary artifacts
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require("fs");
            const ids = JSON.parse(`${{ steps.ingest.outputs.ids }}`);
            fs.mkdirSync("incoming", { recursive: true });

            for (const id of ids) {
              const arts = await github.rest.actions.listWorkflowRunArtifacts({
                owner: context.repo.owner,
                repo: context.repo.repo,
                run_id: id
              });

              for (const a of arts.data.artifacts.filter(x => x.name.startsWith("run-summary"))) {
                const dl = await github.rest.actions.downloadArtifact({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  artifact_id: a.id,
                  archive_format: "zip"
                });
                fs.writeFileSync(`incoming/${id}__${a.name}.zip`, Buffer.from(dl.data));
              }
            }

      - name: Unzip artifacts
        run: |
          set -e
          shopt -s nullglob
          files=(incoming/*.zip)

          if [ ${#files[@]} -eq 0 ]; then
            echo "No run-summary artifacts found. Skipping unzip."
            exit 0
          fi

          for z in "${files[@]}"; do
            d="${z%.zip}"
            mkdir -p "$d"
            unzip -o "$z" -d "$d" >/dev/null
          done

      - name: Append to metrics dataset (deduped)
        run: |
          set -e
          mkdir -p metrics
          touch metrics/runs.jsonl

          python <<'PY'
          import json, os

          existing = {}
          if os.path.exists("metrics/runs.jsonl"):
              with open("metrics/runs.jsonl") as f:
                  for line in f:
                      try:
                          r = json.loads(line)
                          key = (r.get("run_id"), r.get("env") or r.get("environment"))
                          existing[key] = r
                      except:
                          pass

          added = 0

          for root, _, files in os.walk("incoming"):
              for name in files:
                  if name == "run_summary.json":
                      path = os.path.join(root, name)

                      parent = os.path.basename(os.path.dirname(path))
                      env = parent.split("__run-summary-")[-1] if "__run-summary-" in parent else "unknown"

                      with open(path) as fh:
                          obj = json.load(fh)

                      obj.setdefault("env", env)
                      obj.setdefault("environment", env)

                      key = (obj.get("run_id"), env)
                      if key not in existing:
                          existing[key] = obj
                          added += 1

          with open("metrics/runs.jsonl", "w") as out:
              for r in sorted(existing.values(), key=lambda x: x.get("timestamp_utc", "")):
                  out.write(json.dumps(r, ensure_ascii=False) + "\n")

          print(f"Added {added} new runs")
          PY
      

      - name: Commit and push
        run: |
          git config user.name "metrics-bot"
          git config user.email "metrics-bot@users.noreply.github.com"
          git add metrics/runs.jsonl
          git commit -m "Metrics update (${GITHUB_RUN_ID})" || echo "No changes"
          git push origin metrics

  publish_dashboard:
    needs: collect
    runs-on: ubuntu-latest
    environment:
      name: github-pages
    steps:
      - uses: actions/checkout@v4
        with:
          ref: metrics

      - run: |
          rm -rf site
          mkdir -p site/data
          cp dashboard/index.html site/index.html
          cp metrics/runs.jsonl site/data/runs.jsonl

      - uses: actions/upload-pages-artifact@v3
        with:
          path: site

      - uses: actions/deploy-pages@v4

  daily_digest:
    needs: publish_dashboard
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          ref: metrics
          fetch-depth: 0

      - name: Build Slack summary from metrics
        id: summary
        run: |
          python <<'PY'
          import json
          import datetime
          from collections import defaultdict

          now = datetime.datetime.now(datetime.timezone.utc)
          cutoff = now - datetime.timedelta(hours=24)

          env_stats = defaultdict(lambda: {"pass": 0, "fail": 0})
          total = 0

          with open("metrics/runs.jsonl", encoding="utf-8") as f:
              for line in f:
                  r = json.loads(line)

                  ts = r.get("timestamp_utc")
                  if not ts:
                      continue

                  try:
                      t = datetime.datetime.fromisoformat(ts.replace("Z", "+00:00"))
                  except Exception:
                      continue

                  if t < cutoff:
                      continue

                  env = r.get("env") or r.get("environment") or "unknown"
                  status = (r.get("status") or "").lower()

                  total += 1
                  if status == "pass":
                      env_stats[env]["pass"] += 1
                  else:
                      env_stats[env]["fail"] += 1

          lines = []
          for env, s in sorted(env_stats.items()):
              lines.append(f"â€¢ *{env}* â†’ âœ… {s['pass']} | âŒ {s['fail']}")

          fail_total = sum(v["fail"] for v in env_stats.values())
          fail_rate = round((fail_total / total * 100), 1) if total else 0

          text = (
              "ðŸ“Š *QA Automation Dashboard (last 24h)*\n\n"
              "*Environment summary:*\n"
              + ("\n".join(lines) if lines else "_No runs in last 24h_")
              + f"\n\nâ€¢ Runs: *{total}*\n"
              + f"â€¢ Fail rate: *{fail_rate}%*\n\n"
              + "ðŸ”— https://dimagi.github.io/dimagi-qa/"
          )

          print(f"SLACK_TEXT<<EOF\n{text}\nEOF")
          PY >> "$GITHUB_OUTPUT"

      - name: Post or update Slack message
        env:
          SLACK_TOKEN: ${{ secrets.SLACK_QA_BOT_TOKEN }}
          CHANNEL_ID: ${{ secrets.SLACK_CHANNEL_ID_DASHBOARD }}
        run: |
          set -e
          MESSAGE="$(cat slack_message.txt)"
  
          STATE_FILE="metrics/slack_state.json"
          mkdir -p metrics
          [ -f "$STATE_FILE" ] || echo "{}" > "$STATE_FILE"
  
          TS=$(jq -r '.dashboard_message_ts // empty' "$STATE_FILE")
  
          if [ -n "$TS" ]; then
            echo "Updating existing Slack message $TS"
            RESP=$(curl -s -X POST https://slack.com/api/chat.update \
              -H "Authorization: Bearer $SLACK_TOKEN" \
              -H "Content-type: application/json" \
              --data "$(jq -n \
                --arg channel "$CHANNEL_ID" \
                --arg ts "$TS" \
                --arg text "$MESSAGE" \
                '{channel:$channel, ts:$ts, text:$text}')")
          else
            echo "Posting new Slack message"
            RESP=$(curl -s -X POST https://slack.com/api/chat.postMessage \
              -H "Authorization: Bearer $SLACK_TOKEN" \
              -H "Content-type: application/json" \
              --data "$(jq -n \
                --arg channel "$CHANNEL_ID" \
                --arg text "$MESSAGE" \
                '{channel:$channel, text:$text}')")
  
            TS=$(echo "$RESP" | jq -r '.ts')
            jq --arg ts "$TS" '.dashboard_message_ts=$ts' "$STATE_FILE" > tmp.json
            mv tmp.json "$STATE_FILE"
          fi

      - name: Commit Slack state
        run: |
          git config user.name "metrics-bot"
          git config user.email "metrics-bot@users.noreply.github.com"
          git add metrics/slack_state.json
          git commit -m "Update Slack dashboard message state" || echo "No changes"
          git push origin metrics
  
